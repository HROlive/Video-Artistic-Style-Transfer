{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Video_Artistic_Style_Transfer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iygZP03eOymf",
        "colab_type": "code",
        "outputId": "c629dbf6-d8f7-4b00-a66d-2fed8b6c34e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAuc2thwQuvO",
        "colab_type": "code",
        "outputId": "9793db3d-f7ed-494a-a99f-7715293df276",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My Drive/CS50_Final_Project/Video_Artistic_Style_Transfer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/CS50_Final_Project/Video_Artistic_Style_Transfer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_sDghy4RpPj",
        "colab_type": "code",
        "outputId": "baa1fc55-6eb0-4b43-da19-811d7ee06852",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# google colab does not come with torch installed\n",
        "\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1073750016 bytes == 0x58596000 @  0x7f8d2fbe82a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTdz1AOVR-rE",
        "colab_type": "code",
        "outputId": "ae1cc1e6-6751-4371-c978-a5e411b79c3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# we will verify that GPU is enabled for this notebook\n",
        "# following should print: CUDA is available!  Training on GPU ...\n",
        "# \n",
        "# if it prints otherwise, then you need to enable GPU: \n",
        "# from Menu > Runtime > Change Runtime Type > Hardware Accelerator > GPU\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# check if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available!  Training on GPU ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSgAs6p2TjcP",
        "colab_type": "code",
        "outputId": "d24af108-ad27-405a-ea5f-c9d11dedfcef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "# we need pillow version of 5.3.0\n",
        "# we will uninstall the older version first\n",
        "!pip uninstall -y Pillow\n",
        "# install the new one\n",
        "!pip install Pillow==5.3.0\n",
        "# import the new one\n",
        "import PIL\n",
        "print(PIL.PILLOW_VERSION)\n",
        "# this should print 5.3.0. If it doesn't, then restart your runtime:\n",
        "# Menu > Runtime > Restart Runtime"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling Pillow-5.3.0:\n",
            "  Successfully uninstalled Pillow-5.3.0\n",
            "Collecting Pillow==5.3.0\n",
            "  Using cached https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Installing collected packages: Pillow\n",
            "Successfully installed Pillow-5.3.0\n",
            "5.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtMBAFjRN2II",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the necessary packages:\n",
        "import cv2\n",
        "import glob\n",
        "from PIL import Image\t\t\t\t\t\t\t            # Python Image Library for image processing\n",
        "import matplotlib.pyplot as plt \t            # Plotting\n",
        "import numpy as np \t\t\t\t\t\t\t\t            # Numerical computation\n",
        "import torch \t\t\t\t\t\t\t\t                  # Neural network computation\n",
        "from torch import optim\t\t\t\t\t\t            # optimizer to minimize the loss function\n",
        "from torchvision import transforms, models\t\t# Transformations on images and pre-trained models\n",
        "import os, os.path \t\t\t\t\t\t\t\t            # To count the number of image files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpVE0dcjN5TJ",
        "colab_type": "code",
        "outputId": "5c40da84-36e2-42d2-a6d7-40efa5c4a1f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# LOAD VGG19 (features only):\n",
        "# vgg19.features \t: It consists of all the convolutional and pooling layers\n",
        "# vgg19.classifier \t: It consists of the 3 linear classifier layers at the end\n",
        "\n",
        "# We load in the pre-trained model and freeze the weights:\n",
        "styleTransferModel = models.vgg19(pretrained=True).features\n",
        "\n",
        "# Freeze all the VGG parameters since we are only optimizing the target image:\n",
        "for params in styleTransferModel.parameters():\n",
        "\tparams.requires_grad_(False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.torch/models/vgg19-dcbb9e9d.pth\n",
            "100%|██████████| 574673361/574673361 [00:06<00:00, 82195845.26it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "br-SbR_BN_S9",
        "colab_type": "code",
        "outputId": "eb28c497-70fa-432d-c8cf-e7eb9aab0b82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "# Check if GPU is available:\n",
        "if torch.cuda.is_available():\n",
        "\tdevice = torch.device(\"cuda\")\n",
        "\tprint(\"Running on GPU\")\n",
        "else:\n",
        "\tdevice = torch.device(\"cpu\")\n",
        "\tprint(\"Running on CPU\")\n",
        "\n",
        "# Move the model to the GPU if available:\n",
        "styleTransferModel.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on GPU\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (1): ReLU(inplace)\n",
              "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (3): ReLU(inplace)\n",
              "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (6): ReLU(inplace)\n",
              "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (8): ReLU(inplace)\n",
              "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (11): ReLU(inplace)\n",
              "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (13): ReLU(inplace)\n",
              "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (15): ReLU(inplace)\n",
              "  (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (17): ReLU(inplace)\n",
              "  (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (20): ReLU(inplace)\n",
              "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (22): ReLU(inplace)\n",
              "  (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (24): ReLU(inplace)\n",
              "  (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (26): ReLU(inplace)\n",
              "  (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (29): ReLU(inplace)\n",
              "  (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (31): ReLU(inplace)\n",
              "  (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (33): ReLU(inplace)\n",
              "  (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (35): ReLU(inplace)\n",
              "  (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyo-yDUJOBTF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the content and style images:\n",
        "def load_image(image_path, max_size=400, shape=None):\n",
        "\t# Load in an image and make sure that it is <= 400 pixels in the X-Y dimension:\n",
        "\t# Convert the image to RGB:\n",
        "\timage = Image.open(image_path).convert('RGB')\n",
        "\n",
        "\t# Resize the image as a large image will slow down processing:\n",
        "\tif max(image.size) > max_size:\n",
        "\t\timg_size = max_size\n",
        "\telse:\n",
        "\t\timg_size = max(image.size)\n",
        "\n",
        "\tif shape is not None:\n",
        "\t\timg_size = shape\n",
        "\n",
        "\timg_transform = transforms.Compose([\n",
        "\t\t\t\t\t\t\t\t\t\ttransforms.Resize(img_size),\n",
        "\t\t\t\t\t\t\t\t\t\ttransforms.ToTensor(),\n",
        "\t\t\t\t\t\t\t\t\t\ttransforms.Normalize((0.485, 0.456, 0.406),\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t(0.229, 0.224, 0.225))])\n",
        "\t# Discard the transparent alpha channel (that's the :3) and add the batch dimension:\n",
        "\timage = img_transform(image)[:3, :, :].unsqueeze(0)\n",
        "\n",
        "\treturn image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZQJkUfLOEzW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CONTENT AND STYLE FEATURES:\n",
        "# Map the layer names to the names given in the paper:\n",
        "def get_features(image, model, layers=None):\n",
        "\t# Run an image forward through a model and get the features for a set of layers:\n",
        "\n",
        "\t# Layers for the content and style representation of an image:\n",
        "\tif layers is None:\n",
        "\t\tlayers = {'0': 'conv1_1',\n",
        "\t\t\t\t  '5': 'conv2_1',\n",
        "\t\t\t\t  '10': 'conv3_1',\n",
        "\t\t\t\t  '19': 'conv4_1',\n",
        "\t\t\t\t  '21': 'conv4_2',\t\t# Content representation\n",
        "\t\t\t\t  '28': 'conv5_1',}\n",
        "\n",
        "\tfeatures = {}\n",
        "\tx = image\n",
        "\t# model._modules is a dictionary holding each module in the model:\n",
        "\tfor name, layer in model._modules.items():\n",
        "\t\tx = layer(x)\n",
        "\t\tif name in layers:\n",
        "\t\t\tfeatures[layers[name]] = x\n",
        "\n",
        "\treturn features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umMxhudCOHbc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GRAM MATRIX:\n",
        "# Define the gram matrix of the tensor:\n",
        "def gram_matrix(tensor):\n",
        "\t# Calculate the Gram Matrix of a given tensor:\n",
        "\t# Get the batch_size, depth, height and width of the image:\n",
        "\tbatch_size, depth, height, width = tensor.size()\n",
        "\t#(Sample tensor shape : torch.Size([1, 64, 400, 592]))\n",
        "\t# Here, batch_size = 1, depth = 64, height = 400, width = 592\n",
        "\t\n",
        "\t# Vectorize the input image tensor and add all the feature maps:\n",
        "\ttensor = tensor.view(depth, height * width)\t\n",
        "\t# Transpose the image tensor:\n",
        "\ttensor_t = tensor.t()\n",
        "\t# Compute the gram matrix by multiplying the matrix by its transpose:\n",
        "\tgram = torch.mm(tensor, tensor_t)\n",
        "\n",
        "\t# Return the gram matrix:\n",
        "\treturn gram"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apdv4c_gOJh8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_video_to_frames(video_directory):\n",
        "\t# Load the input video:\n",
        "\tcapture_video = cv2.VideoCapture(video_directory)\n",
        "\t# Read the input frame:\n",
        "\tsuccess, frame = capture_video.read()\n",
        "\t# Set counter for number of frames read:\n",
        "\tcount = 1\n",
        "\n",
        "\twhile success:\n",
        "\t\t# Save the frame that is read:\n",
        "\t\tcv2.imwrite('input_content_frames/frame_%d.jpg' % count, frame)\n",
        "\t\t# Read the next input frame:\n",
        "\t\tsuccess, frame = capture_video.read()\n",
        "\t\tprint(\"Read a new frame: \", count, \"Success: \", success)\n",
        "\t\tcount += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXY8GSCdONr0",
        "colab_type": "code",
        "outputId": "a1d4b143-8d93-4d0b-adb5-7cae295e00a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4250
        }
      },
      "source": [
        "# Split the video into frames:\n",
        "convert_video_to_frames('input_video/sample_video.mp4')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Read a new frame:  1 Success:  True\n",
            "Read a new frame:  2 Success:  True\n",
            "Read a new frame:  3 Success:  True\n",
            "Read a new frame:  4 Success:  True\n",
            "Read a new frame:  5 Success:  True\n",
            "Read a new frame:  6 Success:  True\n",
            "Read a new frame:  7 Success:  True\n",
            "Read a new frame:  8 Success:  True\n",
            "Read a new frame:  9 Success:  True\n",
            "Read a new frame:  10 Success:  True\n",
            "Read a new frame:  11 Success:  True\n",
            "Read a new frame:  12 Success:  True\n",
            "Read a new frame:  13 Success:  True\n",
            "Read a new frame:  14 Success:  True\n",
            "Read a new frame:  15 Success:  True\n",
            "Read a new frame:  16 Success:  True\n",
            "Read a new frame:  17 Success:  True\n",
            "Read a new frame:  18 Success:  True\n",
            "Read a new frame:  19 Success:  True\n",
            "Read a new frame:  20 Success:  True\n",
            "Read a new frame:  21 Success:  True\n",
            "Read a new frame:  22 Success:  True\n",
            "Read a new frame:  23 Success:  True\n",
            "Read a new frame:  24 Success:  True\n",
            "Read a new frame:  25 Success:  True\n",
            "Read a new frame:  26 Success:  True\n",
            "Read a new frame:  27 Success:  True\n",
            "Read a new frame:  28 Success:  True\n",
            "Read a new frame:  29 Success:  True\n",
            "Read a new frame:  30 Success:  True\n",
            "Read a new frame:  31 Success:  True\n",
            "Read a new frame:  32 Success:  True\n",
            "Read a new frame:  33 Success:  True\n",
            "Read a new frame:  34 Success:  True\n",
            "Read a new frame:  35 Success:  True\n",
            "Read a new frame:  36 Success:  True\n",
            "Read a new frame:  37 Success:  True\n",
            "Read a new frame:  38 Success:  True\n",
            "Read a new frame:  39 Success:  True\n",
            "Read a new frame:  40 Success:  True\n",
            "Read a new frame:  41 Success:  True\n",
            "Read a new frame:  42 Success:  True\n",
            "Read a new frame:  43 Success:  True\n",
            "Read a new frame:  44 Success:  True\n",
            "Read a new frame:  45 Success:  True\n",
            "Read a new frame:  46 Success:  True\n",
            "Read a new frame:  47 Success:  True\n",
            "Read a new frame:  48 Success:  True\n",
            "Read a new frame:  49 Success:  True\n",
            "Read a new frame:  50 Success:  True\n",
            "Read a new frame:  51 Success:  True\n",
            "Read a new frame:  52 Success:  True\n",
            "Read a new frame:  53 Success:  True\n",
            "Read a new frame:  54 Success:  True\n",
            "Read a new frame:  55 Success:  True\n",
            "Read a new frame:  56 Success:  True\n",
            "Read a new frame:  57 Success:  True\n",
            "Read a new frame:  58 Success:  True\n",
            "Read a new frame:  59 Success:  True\n",
            "Read a new frame:  60 Success:  True\n",
            "Read a new frame:  61 Success:  True\n",
            "Read a new frame:  62 Success:  True\n",
            "Read a new frame:  63 Success:  True\n",
            "Read a new frame:  64 Success:  True\n",
            "Read a new frame:  65 Success:  True\n",
            "Read a new frame:  66 Success:  True\n",
            "Read a new frame:  67 Success:  True\n",
            "Read a new frame:  68 Success:  True\n",
            "Read a new frame:  69 Success:  True\n",
            "Read a new frame:  70 Success:  True\n",
            "Read a new frame:  71 Success:  True\n",
            "Read a new frame:  72 Success:  True\n",
            "Read a new frame:  73 Success:  True\n",
            "Read a new frame:  74 Success:  True\n",
            "Read a new frame:  75 Success:  True\n",
            "Read a new frame:  76 Success:  True\n",
            "Read a new frame:  77 Success:  True\n",
            "Read a new frame:  78 Success:  True\n",
            "Read a new frame:  79 Success:  True\n",
            "Read a new frame:  80 Success:  True\n",
            "Read a new frame:  81 Success:  True\n",
            "Read a new frame:  82 Success:  True\n",
            "Read a new frame:  83 Success:  True\n",
            "Read a new frame:  84 Success:  True\n",
            "Read a new frame:  85 Success:  True\n",
            "Read a new frame:  86 Success:  True\n",
            "Read a new frame:  87 Success:  True\n",
            "Read a new frame:  88 Success:  True\n",
            "Read a new frame:  89 Success:  True\n",
            "Read a new frame:  90 Success:  True\n",
            "Read a new frame:  91 Success:  True\n",
            "Read a new frame:  92 Success:  True\n",
            "Read a new frame:  93 Success:  True\n",
            "Read a new frame:  94 Success:  True\n",
            "Read a new frame:  95 Success:  True\n",
            "Read a new frame:  96 Success:  True\n",
            "Read a new frame:  97 Success:  True\n",
            "Read a new frame:  98 Success:  True\n",
            "Read a new frame:  99 Success:  True\n",
            "Read a new frame:  100 Success:  True\n",
            "Read a new frame:  101 Success:  True\n",
            "Read a new frame:  102 Success:  True\n",
            "Read a new frame:  103 Success:  True\n",
            "Read a new frame:  104 Success:  True\n",
            "Read a new frame:  105 Success:  True\n",
            "Read a new frame:  106 Success:  True\n",
            "Read a new frame:  107 Success:  True\n",
            "Read a new frame:  108 Success:  True\n",
            "Read a new frame:  109 Success:  True\n",
            "Read a new frame:  110 Success:  True\n",
            "Read a new frame:  111 Success:  True\n",
            "Read a new frame:  112 Success:  True\n",
            "Read a new frame:  113 Success:  True\n",
            "Read a new frame:  114 Success:  True\n",
            "Read a new frame:  115 Success:  True\n",
            "Read a new frame:  116 Success:  True\n",
            "Read a new frame:  117 Success:  True\n",
            "Read a new frame:  118 Success:  True\n",
            "Read a new frame:  119 Success:  True\n",
            "Read a new frame:  120 Success:  True\n",
            "Read a new frame:  121 Success:  True\n",
            "Read a new frame:  122 Success:  True\n",
            "Read a new frame:  123 Success:  True\n",
            "Read a new frame:  124 Success:  True\n",
            "Read a new frame:  125 Success:  True\n",
            "Read a new frame:  126 Success:  True\n",
            "Read a new frame:  127 Success:  True\n",
            "Read a new frame:  128 Success:  True\n",
            "Read a new frame:  129 Success:  True\n",
            "Read a new frame:  130 Success:  True\n",
            "Read a new frame:  131 Success:  True\n",
            "Read a new frame:  132 Success:  True\n",
            "Read a new frame:  133 Success:  True\n",
            "Read a new frame:  134 Success:  True\n",
            "Read a new frame:  135 Success:  True\n",
            "Read a new frame:  136 Success:  True\n",
            "Read a new frame:  137 Success:  True\n",
            "Read a new frame:  138 Success:  True\n",
            "Read a new frame:  139 Success:  True\n",
            "Read a new frame:  140 Success:  True\n",
            "Read a new frame:  141 Success:  True\n",
            "Read a new frame:  142 Success:  True\n",
            "Read a new frame:  143 Success:  True\n",
            "Read a new frame:  144 Success:  True\n",
            "Read a new frame:  145 Success:  True\n",
            "Read a new frame:  146 Success:  True\n",
            "Read a new frame:  147 Success:  True\n",
            "Read a new frame:  148 Success:  True\n",
            "Read a new frame:  149 Success:  True\n",
            "Read a new frame:  150 Success:  True\n",
            "Read a new frame:  151 Success:  True\n",
            "Read a new frame:  152 Success:  True\n",
            "Read a new frame:  153 Success:  True\n",
            "Read a new frame:  154 Success:  True\n",
            "Read a new frame:  155 Success:  True\n",
            "Read a new frame:  156 Success:  True\n",
            "Read a new frame:  157 Success:  True\n",
            "Read a new frame:  158 Success:  True\n",
            "Read a new frame:  159 Success:  True\n",
            "Read a new frame:  160 Success:  True\n",
            "Read a new frame:  161 Success:  True\n",
            "Read a new frame:  162 Success:  True\n",
            "Read a new frame:  163 Success:  True\n",
            "Read a new frame:  164 Success:  True\n",
            "Read a new frame:  165 Success:  True\n",
            "Read a new frame:  166 Success:  True\n",
            "Read a new frame:  167 Success:  True\n",
            "Read a new frame:  168 Success:  True\n",
            "Read a new frame:  169 Success:  True\n",
            "Read a new frame:  170 Success:  True\n",
            "Read a new frame:  171 Success:  True\n",
            "Read a new frame:  172 Success:  True\n",
            "Read a new frame:  173 Success:  True\n",
            "Read a new frame:  174 Success:  True\n",
            "Read a new frame:  175 Success:  True\n",
            "Read a new frame:  176 Success:  True\n",
            "Read a new frame:  177 Success:  True\n",
            "Read a new frame:  178 Success:  True\n",
            "Read a new frame:  179 Success:  True\n",
            "Read a new frame:  180 Success:  True\n",
            "Read a new frame:  181 Success:  True\n",
            "Read a new frame:  182 Success:  True\n",
            "Read a new frame:  183 Success:  True\n",
            "Read a new frame:  184 Success:  True\n",
            "Read a new frame:  185 Success:  True\n",
            "Read a new frame:  186 Success:  True\n",
            "Read a new frame:  187 Success:  True\n",
            "Read a new frame:  188 Success:  True\n",
            "Read a new frame:  189 Success:  True\n",
            "Read a new frame:  190 Success:  True\n",
            "Read a new frame:  191 Success:  True\n",
            "Read a new frame:  192 Success:  True\n",
            "Read a new frame:  193 Success:  True\n",
            "Read a new frame:  194 Success:  True\n",
            "Read a new frame:  195 Success:  True\n",
            "Read a new frame:  196 Success:  True\n",
            "Read a new frame:  197 Success:  True\n",
            "Read a new frame:  198 Success:  True\n",
            "Read a new frame:  199 Success:  True\n",
            "Read a new frame:  200 Success:  True\n",
            "Read a new frame:  201 Success:  True\n",
            "Read a new frame:  202 Success:  True\n",
            "Read a new frame:  203 Success:  True\n",
            "Read a new frame:  204 Success:  True\n",
            "Read a new frame:  205 Success:  True\n",
            "Read a new frame:  206 Success:  True\n",
            "Read a new frame:  207 Success:  True\n",
            "Read a new frame:  208 Success:  True\n",
            "Read a new frame:  209 Success:  True\n",
            "Read a new frame:  210 Success:  True\n",
            "Read a new frame:  211 Success:  True\n",
            "Read a new frame:  212 Success:  True\n",
            "Read a new frame:  213 Success:  True\n",
            "Read a new frame:  214 Success:  True\n",
            "Read a new frame:  215 Success:  True\n",
            "Read a new frame:  216 Success:  True\n",
            "Read a new frame:  217 Success:  True\n",
            "Read a new frame:  218 Success:  True\n",
            "Read a new frame:  219 Success:  True\n",
            "Read a new frame:  220 Success:  True\n",
            "Read a new frame:  221 Success:  True\n",
            "Read a new frame:  222 Success:  True\n",
            "Read a new frame:  223 Success:  True\n",
            "Read a new frame:  224 Success:  True\n",
            "Read a new frame:  225 Success:  True\n",
            "Read a new frame:  226 Success:  True\n",
            "Read a new frame:  227 Success:  True\n",
            "Read a new frame:  228 Success:  True\n",
            "Read a new frame:  229 Success:  True\n",
            "Read a new frame:  230 Success:  True\n",
            "Read a new frame:  231 Success:  True\n",
            "Read a new frame:  232 Success:  True\n",
            "Read a new frame:  233 Success:  True\n",
            "Read a new frame:  234 Success:  True\n",
            "Read a new frame:  235 Success:  True\n",
            "Read a new frame:  236 Success:  True\n",
            "Read a new frame:  237 Success:  True\n",
            "Read a new frame:  238 Success:  True\n",
            "Read a new frame:  239 Success:  True\n",
            "Read a new frame:  240 Success:  True\n",
            "Read a new frame:  241 Success:  True\n",
            "Read a new frame:  242 Success:  True\n",
            "Read a new frame:  243 Success:  True\n",
            "Read a new frame:  244 Success:  True\n",
            "Read a new frame:  245 Success:  True\n",
            "Read a new frame:  246 Success:  True\n",
            "Read a new frame:  247 Success:  True\n",
            "Read a new frame:  248 Success:  True\n",
            "Read a new frame:  249 Success:  False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3th2rfaYOPqt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to un-normalize an image and convert from a Tensor image to a NumPy image for display or writing to disk:\n",
        "def img_convert(tensor):\n",
        "\t# Display a tensor as an image:\n",
        "\n",
        "\timage = tensor.to(\"cpu\").clone().detach()\n",
        "\timage = image.numpy().squeeze()\n",
        "\timage = image.transpose(1, 2, 0)\n",
        "\timage = image * np.array((0.229, 0.224, 0.225)) + np.array((0.485, 0.456, 0.406))\n",
        "\timage = image.clip(0, 1)\n",
        "\n",
        "\treturn image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ag1fOcQORyl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def apply_style_transfer(content_img_dir, style_img_dir):\n",
        "\tcontent_image_count = 1\n",
        "\tstyle_image_count = 1\n",
        "\t\n",
        "\t# Retrieve the total number of content image frames and style frames:\n",
        "\tnum_content_imgs = len([name for name in os.listdir(content_img_dir) if os.path.isfile(os.path.join(content_img_dir, name))])\n",
        "\tnum_style_imgs = len([name for name in os.listdir(style_img_dir) if os.path.isfile(os.path.join(style_img_dir, name))])\n",
        "\t# Divide the style images equally among the input frames:\n",
        "\tframes_with_current_style = num_content_imgs // (num_style_imgs - 1)\n",
        "\n",
        "\t# Since there are 249 frames in the test video, you can use for loop, but prefer using while to avoid using magic numbers (hardcoding)\n",
        "\twhile(content_image_count <= num_content_imgs): \n",
        "\t#for i in range(1, 250):\n",
        "\t\t# Load in the content and style images and move them to the GPU if available:\n",
        "\t\tcontent_image = load_image(content_img_dir + '/frame_' + str(content_image_count) + '.jpg').to(device)\n",
        "\t\tif(content_image_count % frames_with_current_style == 0):\n",
        "\t\t\tstyle_image_count += 1\n",
        "\n",
        "\t\tstyle_image = load_image(style_img_dir + '/style_' + str(style_image_count) + '.jpg', shape=content_image.shape[-2:]).to(device)\n",
        "\n",
        "\t\t# Retrieve the features:\n",
        "\t\tcontent_features = get_features(content_image, styleTransferModel)\n",
        "\t\tstyle_features = get_features(style_image, styleTransferModel)\n",
        "\n",
        "\t\t# Calculate the gram matrix for each of our style representations:\n",
        "\t\tstyle_grams = {layer: gram_matrix(style_features[layer]) for layer in style_features}\n",
        "\n",
        "\t\t# We create a 'target image'. Note that, we are starting with the content image and cloning it instead of creating an image with white filter:\n",
        "\t\t# We want to update our image based on the total loss and so we will turn on the gradients:\n",
        "\t\ttarget_image = content_image.clone().requires_grad_(True).to(device)\n",
        "\n",
        "\t\t# LOSS AND WEIGHTS:\n",
        "\t\t# We assign weights for each style layer. Weighting earlier layers more will result in *larger* style artifacts:\n",
        "\t\t# Notice we are excluding `conv4_2`, i.e. our content representation:\n",
        "\t\tstyle_weights = {'conv1_1': 1.,\t\t\t# More style will come from earlier layers as they are weighted more\n",
        "\t\t                 'conv2_1': 0.8,\n",
        "\t\t                 'conv3_1': 0.2,\n",
        "\t\t                 'conv4_1': 0.2,\n",
        "\t\t                 'conv5_1': 0.2}\t\t# Less style from later layers\n",
        "\n",
        "\t\tcontent_weight = 1  # alpha\n",
        "\t\tstyle_weight = 1e8  # beta, 1e6 = 1000000.0\n",
        "\n",
        "\t\t# Iteration hyperparameters:\n",
        "\t\t# Update the target image (as we update the model.parameters() in the classifiers):\n",
        "\t\toptimizer = optim.Adam([target_image], lr=0.003)\n",
        "\t\t# Number of iterations to update your image:\n",
        "\t\tsteps = 2000\n",
        "\t\tshow_every = 1000\n",
        "\t\tfor ii in range(1, steps+1):\n",
        "\n",
        "\t\t\t# Get the features from the target image:\n",
        "\t\t\ttarget_features = get_features(target_image, styleTransferModel)\n",
        "\t\t\t\n",
        "\t\t\t# 1. Calculate the content loss:\n",
        "\t\t\tcontent_loss = torch.mean((target_features['conv4_2'] - content_features['conv4_2']) ** 2)\n",
        "\n",
        "\t\t\t# 2. Calculate the style loss:\n",
        "\t\t\tstyle_loss = 0\n",
        "\t\t\t# iterate through each style layer and add to the style loss:\n",
        "\t\t\tfor layer in style_weights:\n",
        "\t\t\t\t# Get the \"target\" style representation for the layer:\n",
        "\t\t\t\ttarget_feature = target_features[layer]\n",
        "\t\t\t\tbatch_size, depth, height, width = target_feature.shape\n",
        "\n",
        "\t\t\t\t# Calculate the target gram matrix:\n",
        "\t\t\t\ttarget_gram = gram_matrix(target_feature)\n",
        "\n",
        "\t\t\t\t# Get the \"style\" from the style gram matrices computed earlier:\n",
        "\t\t\t\tstyle_gram = style_grams[layer]\n",
        "\n",
        "\t\t\t\t# the style loss for one layer, weighted appropriately:\n",
        "\t\t\t\tlayer_style_loss = style_weights[layer] * torch.mean((target_gram - style_gram) ** 2)\n",
        "\n",
        "\t\t\t\t# Add to the style loss:\n",
        "\t\t\t\tstyle_loss += layer_style_loss / (depth * height * width)\n",
        "\n",
        "\t\t\t# Calculate the total loss:\n",
        "\t\t\ttotal_loss = content_weight * content_loss + style_weight * style_loss\n",
        "\n",
        "\t\t\t# Update the target image:\n",
        "\t\t\toptimizer.zero_grad()\t\t\t# zero out the gradients from previous iterations\n",
        "\t\t\ttotal_loss.backward()\t\t\t# Backpropagate the loss\n",
        "\t\t\toptimizer.step()\t\t\t\t# Update the target image\n",
        "\n",
        "\t\t\t# Display the intermediate results if required:\n",
        "\t\t\t#if ii % show_every == 0:\n",
        "\t\t\t\t#print(\"Total loss: \", total_loss.item())\n",
        "\t\t\t\t#plt.imshow(img_convert(target_image))\n",
        "\t\t\t\t#plt.show()\n",
        "\n",
        "\t\t# Save the style transferred image:\n",
        "\t\ttarget_image = img_convert(target_image)\n",
        "\t\tplt.imsave('output_style_transferred_frames/st_frame_%d.jpg' % content_image_count, target_image)\n",
        "\t\tprint(\"completed style transfer on image: \", content_image_count)\n",
        "\t\tcontent_image_count += 1\n",
        "\t\tif(content_image_count <= 250):\n",
        "\t\t\tcontinue"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7JC9XscOWhD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Apply style transfer on the input frames:\n",
        "apply_style_transfer('input_content_frames', 'input_style_frames')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgqJvGuCOZML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert the final images to video:\n",
        "def img_to_video(st_output_dir):\n",
        "\timg = cv2.imread(st_output_dir + '/st_frame_1.jpg')\n",
        "\theight, width, layers = img.shape\n",
        "\tfourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "\tvideo = cv2.VideoWriter('output_processed_video/style_transfered_video.avi', fourcc, 25, (width, height))\n",
        "\tfor i in range(1, 250):\n",
        "\t\tvideo.write(cv2.imread(st_output_dir + '/st_frame_' + str(i) + '.jpg'))\n",
        "\n",
        "\tcv2.destroyAllWindows()\n",
        "\tvideo.release()\n",
        "\n",
        "img_to_video('output_style_transferred_frames')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}